# **ğŸ“š Japanese Syllabus Check AI System (SpaCy + OpenAI API)**

This application analyzes university syllabuses in Japanese using **SpaCy** for NLP parsing and **OpenAI API** for embedding-based similarity checking.

---

## **ğŸ”§ 1ï¸âƒ£ Installation (Windows CMD)**

### **ğŸ”¹ Step 1: Clone the Repository & Set Up Virtual Environment**
```cmd
git clone https://github.com/yourusername/Syllabus_Spacy.git
cd Syllabus_Spacy
python -m venv transform
transform\Scripts\activate
pip install -r requirements.txt
```

---

## **ğŸš€ 2ï¸âƒ£ Running the Application Locally**

### **ğŸ”¹ Run API Server (FastAPI)**
```cmd
uvicorn main:app --reload
```
- **Access API at:** `http://127.0.0.1:8000`

### **ğŸ”¹ Run Bulk Processing**
```cmd
python app/bulk_process.py --request_id sample_id
```

### **ğŸ”¹ Run Individual Processing**
```cmd
python app/individual_process.py --request_id sample_id "Some text to process"
```

---

## **â˜ï¸ 3ï¸âƒ£ Deploying to AWS**

### **ğŸ”¹ Step 1: Push to GitHub**
```cmd
git add .
git commit -m "Updated application with SpaCy and OpenAI API"
git push origin main
```

### **ğŸ”¹ Step 2: Deploy to AWS Lambda**
1. **Zip the project folder**
```cmd
cd Syllabus_Spacy
zip -r syllabus_lambda.zip *
```
2. **Upload to AWS Lambda**
   - Open **AWS Lambda** â†’ Create Function  
   - Select **Upload from .zip file**  
   - Set **Handler** to `main.lambda_handler`  
   - Attach IAM Role **with S3 & API Gateway permissions**  

### **ğŸ”¹ Step 3: Setup API Gateway**
1. Open **AWS API Gateway** â†’ Create **New REST API**  
2. Add **/process** route â†’ **Connect to Lambda**  
3. Deploy API â†’ Copy **Invoke URL**  
4. Test API using:  
```cmd
curl -X POST https://your-api-url.amazonaws.com/process -d '{"request_id": "sample_id"}'
```

---

## **ğŸ› ï¸ 4ï¸âƒ£ Deploying Using development.sh**

### **ğŸ”¹ Step 1: Load Environment Variables**
```cmd
source .env.develop
```

### **ğŸ”¹ Step 2: Run Deployment Script**
```cmd
sh deploy/development.sh
```

âœ… This will **build, tag, push** the Docker image and **update the ECS service** with the latest version.

---

## **ğŸ¯ 6ï¸âƒ£ Summary of How Everything Connects**

| **File** | **Role** | **Related To** |
|----------------------------|-------------------------------------------------|--------------------------------|
| `bulk_process.py` | Runs bulk syllabus processing | Calls `text_processing.py`, `embedding_generator.py`, `s3_bucket.py`, `webhook.py` |
| `individual_process.py` | Processes single syllabus entry | Calls `embedding_generator.py` |
| `embedding_generator.py` | Generates text embeddings | Uses OpenAI API |
| `text_processing.py` | Parses Japanese text | Uses SpaCy |
| `s3_bucket.py` | Handles S3 interactions | Called by `bulk_process.py`, `individual_process.py` |
| `webhook.py` | Notifies results | Triggered after S3 upload |
| `main.py` | FastAPI entry point | Calls `syllabus_check.py` |
| `syllabus_check.py` | API endpoint handler | Calls `bulk_process.py` & `individual_process.py` |

---

## **ğŸš€ Next Steps**
1ï¸âƒ£ **Test Locally:** Run **FastAPI + processing scripts**.  
2ï¸âƒ£ **Push to GitHub:** Deploy AWS Lambda & API Gateway.  
3ï¸âƒ£ **Final Debugging:** Ensure Webhook & S3 work as expected.  

ğŸ”¥ Now your app is fully functional, structured, and ready for production!

